{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of training procedure using Trainer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainer import Trainer\n",
    "from unet import UNet\n",
    "from dataset import SegmentationDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the configuration parameters\n",
    "\n",
    "TRAIN_IMG_DIR = \"data/train_images/\"\n",
    "TRAIN_MASK_DIR = \"data/train_masks/\"\n",
    "VAL_IMG_DIR = \"data/val_images/\"\n",
    "VAL_MASK_DIR = \"data/val_masks/\"\n",
    "IMAGE_WIDTH = 256\n",
    "IMAGE_HEIGHT = 256\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4\n",
    "PIN_MEMORY = True\n",
    "NUM_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "\n",
    "model = UNet(in_channels=3, out_channels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transforms\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),    # 50% chance of flipping the image\n",
    "    A.Rotate(5),                # rotate +/- 5 degrees\n",
    "    A.RandomResizedCrop(width=IMAGE_WIDTH, height=IMAGE_HEIGHT, scale=(0.1, 1.0)),  # crop the image\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.CenterCrop(IMAGE_HEIGHT*8, IMAGE_WIDTH*8),\n",
    "    A.Resize(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "    # A.RandomCrop(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the datasets and dataloaders\n",
    "\n",
    "train_dataset = SegmentationDataset(TRAIN_IMG_DIR, TRAIN_MASK_DIR, transform=train_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY, shuffle=True)\n",
    "\n",
    "val_dataset = SegmentationDataset(VAL_IMG_DIR, VAL_MASK_DIR, transform=val_transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [0/1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 9/9 [01:25<00:00,  9.47s/it, loss=-1.1]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: -0.1966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 4/4 [00:21<00:00,  5.36s/it, loss=0.623]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6214  -  Accuracy: 0.6718  -  Dice Score: 1.1918\n",
      "\n",
      "Epoch [1/1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 9/9 [01:09<00:00,  7.70s/it, loss=-3.04] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: -2.0491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 4/4 [00:23<00:00,  5.89s/it, loss=0.614]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.5848  -  Accuracy: 0.8065  -  Dice Score: 0.8332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize a trainer object and train the model\n",
    "\n",
    "trainer = Trainer(model, train_loader, val_loader)\n",
    "train_loss, val_loss, val_accuracy, val_dice = trainer.train(num_epochs=NUM_EPOCHS, save_interval=5, save_val_img=True, save_train_img=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the training and validation loss\n",
    "plt.figure()\n",
    "plt.plot(train_loss, label=\"train loss\")\n",
    "plt.plot(val_loss, label=\"validation loss\")\n",
    "plt.legend()\n",
    "plt.savefig(\"loss.png\")\n",
    "plt.show()\n",
    "\n",
    "# Plot the validation accuracy\n",
    "plt.figure()\n",
    "plt.plot(val_accuracy, label=\"validation accuracy\")\n",
    "plt.savefig(\"accuracy.png\")\n",
    "plt.show()\n",
    "\n",
    "# Plot the validation dice\n",
    "plt.figure()\n",
    "plt.plot(val_dice, label=\"validation dice\")\n",
    "plt.savefig(\"dice.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "software",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
